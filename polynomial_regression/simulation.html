<!DOCTYPE html>
<html lang="en-US">

<head>
  <title>Polynomial Regression | Visualize It</title>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="keyword" content="polynomial regression, regression, polynomial, optimization, machine learning, interactive">
  <meta name="og:image" content="https://github.com/visualize-it/visualize-it.github.io/raw/main/images_webp/polynomial_regression.webp">

  <!-- Materialize -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>

  <script src="../helper.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/9.4.5/math.js" defer></script>
  <script src="basic.js" defer></script>
  <script src="user_input.js" defer></script>
  <script src="polynomial_regression.js" defer></script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

  <!-- CSS -->
  <link rel="stylesheet" href="../style.css" />
</head>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-M95CKRP8HB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { window.dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-M95CKRP8HB');
</script>

<body>
  <nav class="nav-extended" style="background:black; margin-top: 0mm">
    <div class="nav-wrapper">
      <h1 id="main-heading">Visualize It</h1>
    </div>
    <div class="nav-content">
      <ul class="tabs tabs-transparent tabs-fixed-width">
        <li class="tab"><a href="../index.html">Home</a></li>
        <li class="tab"><a href="../about.html">About</a></li>
      </ul>
    </div>
  </nav>
</body>

<div class="text">
  <h2>Polynomial Regression</h2>
  <center>
    <p>Polynomial regression is used to find the coefficients of an m-degree polynomial that best fits the given set of
      points.</p>
  </center>
  <br>
  <div class="container" style="width: 90%">
    <div class="row">
      <div class="col s12 l8">
        <center>
          <canvas id="canvas"></canvas>
        </center>
      </div>
      <div class="col s12 l4">
        <center>
          <b>Click on the canvas to introduce a point <br> Click on a point to remove it</b>
          <br> <br>
          <button class="btn purple darken-4" onclick="clearPoints()">Clear Points</button>
          <p id="m-display"></p>
          <input type="range" id="m-input" min="0" max="12" step="1" oninput="updateParams('m')"
            onchange="updateParams('m')">

          <p id="c-display"></p>
          <b id="warn-display">
            Proper fitting with a polynomial of degree m requires atleast m+1 points.
          </b>
        </center>
      </div>
    </div>
  </div>

  <br>
  <hr>

  <h3>Description</h3>
  <p>
    Consider a polynomial of degree m:
    \[ p_m (x) = \theta_0 + \theta_1 x + \theta_2 x^2 + \dots + \theta_m x^m \]
    Polynomial regression allows us to find the coefficients of this polynomial that best fit the given set of \(n\)
    points. The cost function \( J(\theta) \) expresses the error between the polynomial and the given set of points.
    It is given by:
    \[ J(\theta) = \sum_{i = 1}^{n} (y_i - p_m (x_i))^2 \]
    where \( (x_i, y_i) \) are the given points. A lower value of this function indicates a better fit. Hence, we need
    to find the minimum of this function. Calculus dictates that at the minimum of this function:
    \[ \frac{d(J(\theta))}{d\theta} = 0 \]
    The above equation is split into \( m+1 \) equations in \(\theta\), where each equation corresponds to a particular
    power of \( x \) in the polynomial. This system of equations can be better expressed (using linear algebra) in the
    form \( A \vec{\theta} = B \). Solving this system of equations (using Gaussain elimination or inversion of \(A\))
    gives us the value of \(\theta\)'s for which the cost function is minimized. The corresponding polynomial is the
    best fit to the given set of points.
  </p>

  <p>
    Please refer to <a target="_blank" href="http://polynomialregression.drque.net/math.html">this website</a> for
    viewing the exact mathematics involved in polynomial regression.
  </p>

  <br>
  <hr>
  <br>

  <b>Note:</b>
  <ol>
    <li>A set of n points can be exactly fitted with a polynomial of degree n-1. This is the general analogue of the
      fact that there is always a line (which is a 1 dimensional polynomial) joining 2 points.</li>
    <li>A polynomial of degree m requires atleast m+1 points for a proper fit. If this condition is not satisfied, then
      the extra coefficients will be extremely low or zero, which badly skewes the curve.</li>
    <li><a href="../gradient_descent/simulation.html">Gradient Descent</a> can be used for polynomial regression too,
      and adopts an iterative approach to find the best fit. It turns out that this method does not scale well, as the
      number of points and the degree of polynomial increases.</li>
  </ol>

  <br>
  <hr>

  <p class="center-align">Developed by ChanRT | Fork me at <a href="https://www.github.com/chanrt">GitHub</a></p>
</div>

</html>